version: '3.8'

services:
  landppt:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    image: landppt:latest
    container_name: landppt-app
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      # Application Configuration
      - HOST=0.0.0.0
      - PORT=8000
      - DEBUG=false
      - RELOAD=false
      
      # Security Configuration
      - SECRET_KEY=${SECRET_KEY:-your-very-secure-secret-key-change-this-in-production}
      - ACCESS_TOKEN_EXPIRE_MINUTES=${ACCESS_TOKEN_EXPIRE_MINUTES:-30}
      
      # Database Configuration
      - DATABASE_URL=sqlite:///./data/landppt.db
      
      # File Configuration
      - MAX_FILE_SIZE=${MAX_FILE_SIZE:-10485760}
      - UPLOAD_DIR=/app/uploads
      - CACHE_TTL=${CACHE_TTL:-3600}
      
      # AI Provider Configuration
      - DEFAULT_AI_PROVIDER=${DEFAULT_AI_PROVIDER:-openai}
      
      # OpenAI Configuration
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-3.5-turbo}
      - OPENAI_BASE_URL=${OPENAI_BASE_URL:-https://api.openai.com/v1}
      
      # Anthropic Configuration
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - ANTHROPIC_MODEL=${ANTHROPIC_MODEL:-claude-3-haiku-20240307}
      
      # Google Gemini Configuration
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      - GOOGLE_MODEL=${GOOGLE_MODEL:-gemini-1.5-flash}
      
      # Azure OpenAI Configuration
      - AZURE_OPENAI_API_KEY=${AZURE_OPENAI_API_KEY}
      - AZURE_OPENAI_ENDPOINT=${AZURE_OPENAI_ENDPOINT}
      - AZURE_OPENAI_DEPLOYMENT_NAME=${AZURE_OPENAI_DEPLOYMENT_NAME}
      - AZURE_OPENAI_API_VERSION=${AZURE_OPENAI_API_VERSION:-2024-02-15-preview}
      
      # Ollama Configuration
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://ollama:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama2}
      
      # Tavily API Configuration
      - TAVILY_API_KEY=${TAVILY_API_KEY}
      - TAVILY_MAX_RESULTS=${TAVILY_MAX_RESULTS:-10}
      - TAVILY_SEARCH_DEPTH=${TAVILY_SEARCH_DEPTH:-advanced}
      
      # AI Generation Parameters
      - MAX_TOKENS=${MAX_TOKENS:-8192}
      - TEMPERATURE=${TEMPERATURE:-0.7}
      - TOP_P=${TOP_P:-1.0}
      
      # Feature Flags
      - ENABLE_NETWORK_MODE=${ENABLE_NETWORK_MODE:-true}
      - ENABLE_LOCAL_MODELS=${ENABLE_LOCAL_MODELS:-false}
      - ENABLE_STREAMING=${ENABLE_STREAMING:-true}
      
      # Logging Configuration
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_AI_REQUESTS=${LOG_AI_REQUESTS:-false}
      
    volumes:
      # Persistent data
      - landppt_data:/app/data
      - landppt_uploads:/app/uploads
      - landppt_temp:/app/temp
      - landppt_research:/app/research_reports
      - landppt_lib:/app/lib
      
    networks:
      - landppt-network
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Optional: Ollama service for local AI models
  ollama:
    image: ollama/ollama:latest
    container_name: landppt-ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - landppt-network
    profiles:
      - ollama
    environment:
      - OLLAMA_ORIGINS=*

volumes:
  landppt_data:
    driver: local
  landppt_uploads:
    driver: local
  landppt_temp:
    driver: local
  landppt_research:
    driver: local
  landppt_lib:
    driver: local
  ollama_data:
    driver: local

networks:
  landppt-network:
    driver: bridge
